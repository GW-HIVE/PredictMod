{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tutorial aims to provide step-by-step instructions for training and testing a Random Forest Classifier with gut microbiome relative abundance data. The metagenomic files were retrieved from SRA accession PRJNA454826 and comprise paired-end whole genome sequencing (WGS) reads. This data was analyzed and processed in the HIVE platform where both HIVE-Hexagon and Censuscope were utilized to perform sequence alignment and taxonomic profiling, respectively. \n",
    "\n",
    "NOTE: Make sure to run, by clicking the arrow key next to the Python code, for each step prior to moving on to the next step to ensure all necessary information is loaded. \n",
    "\n",
    "Step 1: The first step is to import all necessary packages that are needed to conduct this ML training and testing. Run the first python box, and make sure you see \"Ready to Go\" as your output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"Ready to Go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Before you begin the next step make sure the \"upsampled_data.csv\" is saved in the same folder as this tutorial. \n",
    "\n",
    "Step 2: Once you have successfully importated all necessary packages, the next step will uplod the final table that will be used to train and test our random forest classifier (DTC). Successful loading should result in \"Table Loaded\" as the output after running that cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = pd.read_csv(\"upsampled_data.csv\")\n",
    "print(\"Table Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: This next portion splits the dataset into a training and testing set, where 25% of the table will be reserved for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_table.drop([\"Status\", \"Reference\"], axis=1)\n",
    "y = train_table[\"Status\"]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25 ,random_state=123)\n",
    "print(\"Ready to Go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: The next step is to train the random forest and view it's performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state=123)\n",
    "RF.fit(X_train,y_train)\n",
    "print(f'RandomForestClassifier train score: {RF.score(X_train,y_train)}')\n",
    "print(f'RandomForestClassifier test score:  {RF.score(X_test,y_test)}')\n",
    "print(confusion_matrix(y_test, RF.predict(X_test)))\n",
    "print(classification_report(y_test, RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the model is able to predict response outcome at 90% accuracy. Now would be a great opportunity to view the organisms that are being used to make predictions for response outcome. \n",
    "\n",
    "Step 5: Now that we have viewed the performance metrics. The next step is to visualize feature importance. This shows us what bacteria are the most helpful for predicting response to exercise for prediabetes intervention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train_table.columns.drop([\"Reference\", \"Status\"])\n",
    "features = feature_names\n",
    "importances = RF.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "num_features = 10\n",
    "plt.figure(figsize=(16,14))\n",
    "plt.title('Feature Importances')\n",
    "# only plot the customized number of features\n",
    "plt.barh(range(num_features), importances[indices[-num_features:]], color='lightblue', align='center')\n",
    "plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
    "fontsize = 25\n",
    "plt.title(\"Feature Importance of Decision Tree Model\", fontsize=fontsize)\n",
    "plt.xlabel('Relative Importance', fontsize=fontsize)\n",
    "plt.ylabel(\"Features (Bacteria)\", fontsize=fontsize) \n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are several organisms that impact ones ability to be deemed a responder or non-responder to exercise when treating their pre-diabetes status. This is a general view of what the model is using to make predictions off of. There are alternative metrics that can be used to determine response outcome on a patient base. This typically involves something like Shapley value. This will be available on version 2 of the metagenomic Python tutorial. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d5451033965499aba12e4a3836703c313b94142d5b0826ea1f3698ae015f86b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
